{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp049_train_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'local_train'\n",
    "#MODE = 'kaggle_inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'exp049'\n",
    "memo = 'tfidfをname+address+cityに'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "if MODE == 'local_train':\n",
    "    sys.path.append('/home/kaggler/.local/lib/python3.8/site-packages')\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv\n",
    "    sys.path.append(os.getenv('UTILS_PATH'))\n",
    "    import line_notify\n",
    "    import slack_notify\n",
    "    \n",
    "\n",
    "from cuml import ForestInference\n",
    "import treelite\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt; plt.style.use(\"ggplot\")\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import lightgbm as lgb\n",
    "import itertools\n",
    "from scipy.spatial.distance import canberra\n",
    "from cuml.neighbors import KNeighborsRegressor\n",
    "import functools\n",
    "import multiprocessing\n",
    "import Levenshtein\n",
    "import difflib\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "%load_ext Cython\n",
    "\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from cuml.feature_extraction.text import TfidfVectorizer as TfidfVectorizer_gpu\n",
    "import cudf, cuml, cupy\n",
    "from cuml.neighbors import NearestNeighbors as NearestNeighbors_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directry_setting\n",
    "if MODE == 'local_train':\n",
    "    INPUT_DIR = os.getenv('INPUT_DIR')\n",
    "    OUTPUT_DIR = os.getenv('OUTPUT_DIR')\n",
    "    MODEL_DIR = os.getenv('OUTPUT_DIR')\n",
    "    BERT_MODEL = \"distilbert-base-multilingual-cased\"\n",
    "    os.makedirs(OUTPUT_DIR + exp_name, exist_ok=True)\n",
    "\n",
    "elif MODE == 'kaggle_inference':\n",
    "    INPUT_DIR = '/kaggle/input/foursquare-location-matching/'\n",
    "    OUTPUT_DIR = './'\n",
    "    MODEL_DIR = f'../input/fs{exp_name}/'\n",
    "    BERT_MODEL = \"../input/distilbertbaseuncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "SEED = 42\n",
    "N_NEIGHBORS = 15\n",
    "N_SPLITS = 5\n",
    "PROB_TH = 0.5\n",
    "MAX_LEN = 32\n",
    "BS = 512\n",
    "NW = 2\n",
    "SVD_N_COMP = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cat2VecModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cat2VecModel, self).__init__()\n",
    "        self.distill_bert = DistilBertModel.from_pretrained(BERT_MODEL)\n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        x = self.distill_bert(ids, mask)[0]\n",
    "        x = F.normalize((x[:, 1:, :]*mask[:, 1:, None]).mean(axis=1))\n",
    "        return x\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, max_len, col):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True)\n",
    "        self.col = col\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            row[self.col],\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_LEN,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = torch.LongTensor(inputs['input_ids'])\n",
    "        mask = torch.LongTensor(inputs['attention_mask'])\n",
    "\n",
    "        return ids, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "def inference(ds):\n",
    "    cat2vec_model = Cat2VecModel()\n",
    "    cat2vec_model = cat2vec_model.cuda()\n",
    "    \n",
    "    loader = DataLoader(ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                        pin_memory=False, drop_last=False)\n",
    "    \n",
    "    vs = []\n",
    "    with torch.no_grad():\n",
    "        for idx, (ids, masks) in enumerate(loader):\n",
    "            v = cat2vec_model(ids.cuda(), masks.cuda()).detach().cpu().numpy()\n",
    "            vs.append(v)\n",
    "    return np.concatenate(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bert_vec(df, col):\n",
    "    cat_df = df[[col]].drop_duplicates()\n",
    "    cat_df[col] = cat_df[col].fillna(\"null\")\n",
    "\n",
    "    cat_ds = InferenceDataset(cat_df, max_len=MAX_LEN, col=col)\n",
    "    V = inference(cat_ds)\n",
    "    #svd = TruncatedSVD(n_components=SVD_N_COMP, random_state=SEED)\n",
    "    #V = svd.fit_transform(V)\n",
    "    V = V.astype(\"float16\")\n",
    "    bert_vec = {k:v for k,v in zip(cat_df[col].values, V)}\n",
    "    return bert_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    columns = ['id', 'name', 'address', 'city', 'state',\n",
    "        'zip', 'country', 'url', 'phone', 'categories']\n",
    "    for c in columns:\n",
    "        if c != \"id\":\n",
    "            df[c] = df[c].astype(str).str.lower()\n",
    "\n",
    "    df[[\"latitude\", \"longitude\"]] = np.deg2rad(df[[\"latitude\", \"longitude\"]])\n",
    "\n",
    "    df[\"name+address+city\"] = df[\"name\"].replace(\"nan\", \"\") + \" \" + \\\n",
    "                              df[\"address\"].replace(\"nan\", \"\") + \" \" + \\\n",
    "                              df[\"city\"].replace(\"nan\", \"\")\n",
    "\n",
    "    df.loc[((df[\"name\"]==\"nan\") & (df[\"address\"]==\"nan\") & (df[\"city\"]==\"nan\")), \"name+address+city\"] = \"nan\"\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_dist(df):\n",
    "    dfs = []\n",
    "    for country, country_df in tqdm(df.groupby(\"country\")):\n",
    "        country_df = country_df.reset_index(drop=True)\n",
    "        \n",
    "        knn = KNeighborsRegressor(n_neighbors=min(len(country_df), N_NEIGHBORS), \n",
    "                                    metric='haversine', algorithm=\"brute\")\n",
    "        knn.fit(country_df[['latitude','longitude']], country_df.index.values)\n",
    "        nears = knn.kneighbors(country_df[['latitude','longitude']], return_distance=False)\n",
    "        \n",
    "        k = min(len(country_df), N_NEIGHBORS)\n",
    "        country_df['match_id'] = country_df['id'].values[nears[:, :k]].tolist()\n",
    "        country_df = country_df.explode(['match_id'])\n",
    "        country_df = country_df.loc[country_df['id'] != country_df['match_id']].copy()\n",
    "        dfs.append(country_df)\n",
    "    df = pd.concat(dfs).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_tfidf_sim(df, col):\n",
    "    dfs = []\n",
    "    for country, country_df in tqdm(df.groupby(\"country\")):\n",
    "        country_df = country_df[country_df[col]!=\"nan\"].copy()\n",
    "        if len(country_df) < 2:\n",
    "            continue\n",
    "\n",
    "        country_df = country_df.reset_index(drop=True)\n",
    "        \n",
    "        model = TfidfVectorizer(ngram_range=(3,3), analyzer=\"char_wb\", use_idf=True)\n",
    "        text_embeddings = model.fit_transform(country_df[\"name\"].tolist())\n",
    "\n",
    "        model = NearestNeighbors_gpu(n_neighbors=min(len(country_df), N_NEIGHBORS), algorithm=\"brute\")\n",
    "        model.fit(text_embeddings)\n",
    "        nears = model.kneighbors(text_embeddings, return_distance=False)\n",
    "        \n",
    "        k = min(len(country_df), N_NEIGHBORS)\n",
    "        country_df['match_id'] = country_df['id'].values[nears[:, :k]].tolist()\n",
    "        country_df = country_df.explode(['match_id'])\n",
    "        country_df = country_df.loc[country_df['id'] != country_df['match_id']].copy()\n",
    "        dfs.append(country_df)\n",
    "    df = pd.concat(dfs).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_orgin_data(df, org_df):\n",
    "    df = df.merge(org_df.add_prefix('match_'), on='match_id')\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "\n",
    "    \"\"\"\n",
    "    #lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/columbia2131/foursquare-iou-metrics\n",
    "def get_id2poi(input_df: pd.DataFrame) -> dict:\n",
    "    return dict(zip(input_df['id'], input_df['point_of_interest']))\n",
    "\n",
    "def get_poi2ids(input_df: pd.DataFrame) -> dict:\n",
    "    return input_df.groupby('point_of_interest')['id'].apply(set).to_dict()\n",
    "\n",
    "def get_score(input_df: pd.DataFrame, org_data):\n",
    "    scores = []\n",
    "    id2poi = get_id2poi(org_data)\n",
    "    poi2ids = get_poi2ids(org_data)\n",
    "    for id_str, matches in zip(input_df['id'].to_numpy(), input_df['matches'].to_numpy()):\n",
    "        targets = poi2ids[id2poi[id_str]]\n",
    "        preds = set(matches.split())\n",
    "        score = len((targets & preds)) / len((targets | preds))\n",
    "        scores.append(score)\n",
    "    scores = np.array(scores)\n",
    "    return scores.mean()\n",
    "\n",
    "def calc_max_score(tr_data, org_data):\n",
    "    train_candidate = pd.DataFrame()\n",
    "    train_candidate['id'] = org_data['id'].unique()\n",
    "    train_candidate['matches'] = org_data['id'].unique()\n",
    "    idx = tr_data['point_of_interest']==tr_data['match_point_of_interest']\n",
    "    train_match = tr_data.loc[idx].groupby('id')['match_id'].apply(list).map(\" \".join).reset_index()\n",
    "    train_match.columns = ['id','candidates']\n",
    "    train_candidate = train_candidate.merge(train_match, on = 'id', how = 'left')\n",
    "    idx = ~train_candidate['candidates'].isna()\n",
    "    train_candidate.loc[idx, \"matches\"] += \" \" + train_candidate.loc[idx, \"candidates\"]\n",
    "    score = get_score(train_candidate, org_data)\n",
    "    print('1st_stage_max_score : ' + '{:.5f}'.format(score))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_similarity(A, B):\n",
    "    if not A or not B:\n",
    "        return -1\n",
    "\n",
    "    A = set(str(A).split(\", \"))\n",
    "    B = set(str(B).split(\", \"))\n",
    "\n",
    "    # Find intersection of two sets\n",
    "    nominator = A.intersection(B)\n",
    "\n",
    "    similarity_1 = len(nominator) / len(A)\n",
    "    similarity_2 = len(nominator) / len(B)\n",
    "\n",
    "    return max(similarity_1, similarity_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "# Optimized version\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "import cython\n",
    "from libc.stdlib cimport malloc, free\n",
    "\n",
    "\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "@cython.wraparound(False)  # turn off negative index wrapping for entire function\n",
    "def LCS(str S, str T):\n",
    "    if len(S) < len(T):\n",
    "        S, T = T, S\n",
    "\n",
    "    cdef int i, j\n",
    "    cdef np.uint16_t[:] dp_prev, dp_curr\n",
    "    \n",
    "    dp_prev = np.zeros(len(T) + 1, dtype=np.uint16)\n",
    "    dp_curr = np.zeros(len(T) + 1, dtype=np.uint16)\n",
    "\n",
    "    for i in range(len(S)):\n",
    "        for j in range(len(T)):\n",
    "            dp_curr[j + 1]  = max(dp_prev[j] + (1 if S[i] == T[j] else 0), dp_curr[j], dp_prev[j + 1])\n",
    "        dp_prev, dp_curr = dp_curr, dp_prev\n",
    "    return dp_prev[len(T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tfidf_vec(df, col):\n",
    "    df_ = pd.concat([df[col], df[\"match_\" + col]]).drop_duplicates().to_frame()\n",
    "    df_ = df_.reset_index(drop=True)\n",
    "    df_.columns = [col]\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(3,3), analyzer=\"char_wb\", use_idf=True)\n",
    "    tfidf_vec = tfidf_vectorizer.fit_transform(df_[col].tolist())\n",
    "    tfidf_vec = {k:v for k,v in zip(df_[col].values, tfidf_vec)}\n",
    "    return tfidf_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tfidf_vec2(df, col):\n",
    "    df_ = pd.concat([df[col], df[\"match_\" + col]]).to_frame()\n",
    "    df_ = df_.reset_index(drop=True)\n",
    "    df_.columns = [col]\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(3,3), analyzer=\"char_wb\", use_idf=True)\n",
    "    tfidf_vec = tfidf_vectorizer.fit_transform(df_[col].tolist())\n",
    "    tfidf_vec1 = tfidf_vec[:len(df)]\n",
    "    tfidf_vec2 = tfidf_vec[len(df):]\n",
    "    return tfidf_vec1, tfidf_vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_distance_features(args):\n",
    "    _, df = args\n",
    "    columns = ['name', 'address', 'city', 'state',\n",
    "               'zip', 'url', 'phone', 'categories']\n",
    "    for c in columns:\n",
    "        geshs = []\n",
    "        levens = []\n",
    "        jaros = []\n",
    "        lcss = []\n",
    "\n",
    "        for i, str_total in enumerate(df[[f\"{c}\", f\"match_{c}\"]].values.astype(str)):\n",
    "            str1 = str_total[0]\n",
    "            str2 = str_total[1]\n",
    "            if str1 != \"nan\" and str2 != \"nan\":\n",
    "                geshs.append(difflib.SequenceMatcher(None, str1, str2).ratio())\n",
    "                levens.append(Levenshtein.distance(str1, str2))\n",
    "                jaros.append(Levenshtein.jaro_winkler(str1, str2))\n",
    "                lcss.append(LCS(str(str1), str(str2)))\n",
    "            else:\n",
    "                geshs.append(-1)\n",
    "                levens.append(-1)\n",
    "                jaros.append(-1)\n",
    "                lcss.append(-1)\n",
    "\n",
    "        df[f\"match_{c}_gesh\"] = geshs\n",
    "        df[f\"match_{c}_gesh\"] = df[f\"match_{c}_gesh\"].astype(np.float16)\n",
    "        df[f\"match_{c}_leven\"] = levens\n",
    "        df[f\"match_{c}_leven\"] = df[f\"match_{c}_leven\"].astype(np.float16)\n",
    "        df[f\"match_{c}_jaro\"] = jaros\n",
    "        df[f\"match_{c}_jaro\"] = df[f\"match_{c}_jaro\"].astype(np.float16)\n",
    "        df[f\"match_{c}_lcs\"] = lcss\n",
    "        df[f\"match_{c}_lcs\"] = df[f\"match_{c}_lcs\"].astype(np.float16)\n",
    "        if not c in ['country', \"phone\", \"zip\"]:\n",
    "            df[f\"match_{c}_len\"] = df[f\"match_{c}\"].astype(str).map(len)\n",
    "            df[f\"{c}_len\"] = df[f\"{c}\"].astype(str).map(len)\n",
    "            df[f\"match_{c}_nleven\"] = df[f\"match_{c}_leven\"] / df[[f\"match_{c}_len\", f\"{c}_len\"]].max(axis=1)\n",
    "            df[f\"match_{c}_nleven\"] = df[f\"match_{c}_nleven\"].astype(np.float16)\n",
    "            df[f\"match_{c}_nlcsi\"] = df[f\"match_{c}_lcs\"] / df[f\"match_{c}_len\"]\n",
    "            df[f\"match_{c}_nlcs0\"] = df[f\"match_{c}_lcs\"] / df[f\"{c}_len\"]\n",
    "            df[f\"match_{c}_nlcsi\"] = df[f\"match_{c}_nlcsi\"].astype(np.float16)\n",
    "            df[f\"match_{c}_nlcs0\"] = df[f\"match_{c}_nlcs0\"].astype(np.float16)\n",
    "            df.drop(f'{c}_len',axis=1, inplace = True)\n",
    "            df.drop(f\"match_{c}_len\",axis=1, inplace = True)\n",
    "\n",
    "    for c in [\"name+address+city\", \"categories\"]:\n",
    "        tfidf_sims = []\n",
    "        tfidf_vec1, tfidf_vec2 = make_tfidf_vec2(df, c)\n",
    "        tfidf_sims = tfidf_vec1.multiply(tfidf_vec2).sum(axis=1).A1\n",
    "\n",
    "        for i, str_total in enumerate(df[[f\"{c}\", f\"match_{c}\"]].values.astype(str)):\n",
    "            str1 = str_total[0]\n",
    "            str2 = str_total[1]\n",
    "            if str1 == \"nan\" or str2 == \"nan\":\n",
    "                tfidf_sims[i] = -1\n",
    "        df[f\"tfidf_sim_{c}\"] = tfidf_sims\n",
    "        df[f\"tfidf_sim_{c}\"] = df[f\"tfidf_sim_{c}\"].astype(np.float16)\n",
    "    return df\n",
    "    \n",
    "def add_distance_features(df):\n",
    "    processes = multiprocessing.cpu_count()\n",
    "    with multiprocessing.Pool(processes=processes) as pool:\n",
    "        dfs = pool.imap_unordered(_add_distance_features, df.groupby('country'))\n",
    "        dfs = tqdm(dfs)\n",
    "        dfs = list(dfs)\n",
    "    df = pd.concat(dfs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vec_sim_features(df, vec, vec_name, col):\n",
    "    sim_list = []\n",
    "    for str1, str2 in tqdm(df[[f\"{col}\", f\"match_{col}\"]].values.astype(str)):\n",
    "        if str1!=\"nan\" and str2!=\"nan\":\n",
    "            sim = dot(vec[str1], vec[str2]) / (norm(vec[str1])*norm(vec[str2]))\n",
    "        else:\n",
    "            sim = -1\n",
    "        sim_list.append(sim)\n",
    "    df[f\"{vec_name}_sim_{col}\"] = sim_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_data_size(df, features):\n",
    "    if MODE == 'local_train':\n",
    "        df = df[features + ['target', 'id', 'match_id']].copy()\n",
    "    elif MODE == 'kaggle_inference':\n",
    "        df = df[features + ['id', 'match_id']].copy()\n",
    "\n",
    "\n",
    "    df[features] = df[features].astype(np.float16)\n",
    "    for _ in range(5):\n",
    "        gc.collect()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, features, cv=False):\n",
    "    params = {'objective': 'binary', \n",
    "              'boosting': 'gbdt',\n",
    "              'learning_rate': 0.1, \n",
    "              'metric': 'binary_logloss', \n",
    "              'seed': SEED, \n",
    "              'feature_pre_filter': False, \n",
    "              'lambda_l1': 0.5745709668124809, \n",
    "              'lambda_l2': 0.5123383865042099, \n",
    "              'num_leaves': 239, \n",
    "              'feature_fraction': 0.784, \n",
    "              'bagging_fraction': 1.0, \n",
    "              'bagging_freq': 0, \n",
    "              'min_child_samples': 5\n",
    "              }\n",
    "\n",
    "    # split folds\n",
    "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    for i, (trn_idx, val_idx) in enumerate(kf.split(df, df[\"target\"], df[\"target\"])):\n",
    "        df.loc[val_idx, \"fold\"] = i\n",
    "    \n",
    "    fi = pd.DataFrame()\n",
    "    oof = df[['id', 'match_id', 'target']].copy()\n",
    "    oof['prob'] = 0.0\n",
    "    scores = []\n",
    "\n",
    "    for i in range(N_SPLITS):\n",
    "        print('fold : ' + str(i))\n",
    "        tr_idx = df[df['fold'] != i].index\n",
    "        vl_idx = df[df['fold'] == i].index\n",
    "        tr_x, tr_y = df.loc[tr_idx, features], df.loc[tr_idx, 'target']\n",
    "        vl_x, vl_y = df.loc[vl_idx, features], df.loc[vl_idx, 'target']\n",
    "        tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "        vl_data = lgb.Dataset(vl_x, label=vl_y)\n",
    "\n",
    "        model = lgb.train(params, tr_data, valid_sets=[tr_data, vl_data],\n",
    "                        num_boost_round=200000, early_stopping_rounds=100, verbose_eval=1000)\n",
    "\n",
    "        # 特徴量重要度\n",
    "        fi_tmp = pd.DataFrame()\n",
    "        fi_tmp['feature'] = model.feature_name()\n",
    "        fi_tmp['importance'] = model.feature_importance(importance_type='gain')\n",
    "        fi_tmp['iter'] = i\n",
    "        fi = fi.append(fi_tmp)\n",
    "\n",
    "        pred = model.predict(vl_x, num_iteration=model.best_iteration)\n",
    "        oof.loc[vl_idx, 'prob'] = pred\n",
    "\n",
    "        score = accuracy_score((pred > PROB_TH).astype(int), vl_y)\n",
    "        scores.append(score)\n",
    "        print(f'fold{i} | accuracy = ' + '{:.5f}'.format(score))\n",
    "        \n",
    "        if cv:\n",
    "            fi_n = fi['feature'].nunique()\n",
    "            order = list(fi.groupby(\"feature\").mean().sort_values(\"importance\", ascending=False).index)\n",
    "            plt.figure(figsize=(10, fi_n*0.2))\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=fi, order=order)\n",
    "            plt.title(f\"LGBM importance\")\n",
    "            plt.tight_layout()\n",
    "            return model\n",
    "\n",
    "        with open(OUTPUT_DIR + f'{exp_name}/model{i}.pickle', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        \n",
    "    oof.to_csv(OUTPUT_DIR + f'{exp_name}/{exp_name}_oof.csv', index=False)\n",
    "\n",
    "    print('accuracy(mean) : ' + '{:.5f}'.format(np.mean(scores)))\n",
    "    print(scores)\n",
    "\n",
    "    fi_n = fi['feature'].nunique()\n",
    "    order = list(fi.groupby(\"feature\").mean().sort_values(\"importance\", ascending=False).index)\n",
    "    plt.figure(figsize=(10, fi_n*0.2))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=fi, order=order)\n",
    "    plt.title(f\"LGBM importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR + f'{exp_name}/lgbm_importance.png')\n",
    "\n",
    "    return oof, np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(df, features):\n",
    "    pred = np.zeros(len(df))\n",
    "    for i in range(N_SPLITS):\n",
    "        with open(MODEL_DIR + f'model{i}.pickle', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        model.save_model(\"test.lgb\")\n",
    "        fi = ForestInference()\n",
    "        fi = ForestInference.load(\"test.lgb\", output_class=True, model_type=\"lightgbm\")\n",
    "        pred += fi.predict(df[features]) / N_SPLITS\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df, org_data):\n",
    "    train_candidate = pd.DataFrame()\n",
    "    train_candidate['id'] = org_data['id'].unique()\n",
    "    train_candidate['matches'] = org_data['id'].unique()\n",
    "\n",
    "    train_match = df[df['prob'] >= PROB_TH].copy()\n",
    "    train_match = train_match.groupby('id')['match_id'].apply(list).map(\" \".join).reset_index()\n",
    "    train_match.columns = ['id','candidates']\n",
    "    train_candidate = train_candidate.merge(train_match, on = 'id', how = 'left')\n",
    "    idx = ~train_candidate['candidates'].isna()\n",
    "    train_candidate.loc[idx, \"matches\"] += \" \" + train_candidate.loc[idx, \"candidates\"]\n",
    "    return train_candidate[['id', 'matches']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(df):\n",
    "    id2match = dict(zip(df[\"id\"].values, df[\"matches\"].str.split()))\n",
    "\n",
    "    for match in tqdm(df[\"matches\"]):\n",
    "        match = match.split()\n",
    "        if len(match) == 1:        \n",
    "            continue\n",
    "\n",
    "        base = match[0]\n",
    "        for m in match[1:]:\n",
    "            if not base in id2match[m]:\n",
    "                id2match[m].append(base)\n",
    "    df[\"matches\"] = df[\"id\"].map(id2match).map(\" \".join)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210/210 [00:19<00:00, 10.69it/s]\n",
      "100%|██████████| 210/210 [00:37<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st_stage_max_score : 0.96829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [15:30,  4.56s/it] \n",
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 15481049/15481049 [04:18<00:00, 59842.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_bert_sim_name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 15481049/15481049 [05:09<00:00, 50017.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/kaggler/.local/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 465078, number of negative: 11919761\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.887947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9137\n",
      "[LightGBM] [Info] Number of data points in the train set: 12384839, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037552 -> initscore=-3.243748\n",
      "[LightGBM] [Info] Start training from score -3.243748\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.0299125\tvalid_1's binary_logloss: 0.0389194\n",
      "[2000]\ttraining's binary_logloss: 0.0213329\tvalid_1's binary_logloss: 0.0342941\n",
      "[3000]\ttraining's binary_logloss: 0.0157766\tvalid_1's binary_logloss: 0.0311197\n",
      "[4000]\ttraining's binary_logloss: 0.0121263\tvalid_1's binary_logloss: 0.0288993\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12603/2589044483.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(df, features, cv)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mvl_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvl_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvl_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         model = lgb.train(params, tr_data, valid_sets=[tr_data, vl_data],\n\u001b[0m\u001b[1;32m     37\u001b[0m                         num_boost_round=200000, early_stopping_rounds=100, verbose_eval=1000)\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    290\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_origin = pd.read_csv(INPUT_DIR + \"train.csv\")\n",
    "train_origin = preprocess(train_origin)\n",
    "\n",
    "# trainデータの分割\n",
    "kf = GroupKFold(n_splits=2)\n",
    "for i, (trn_idx, val_idx) in enumerate(kf.split(train_origin, train_origin['point_of_interest'], train_origin['point_of_interest'])):\n",
    "    train_origin.loc[val_idx, \"set\"] = i\n",
    "# cv用にデータ分割\n",
    "test_origin = train_origin[train_origin[\"set\"]==1].copy()\n",
    "test_origin = test_origin.reset_index(drop=True)\n",
    "train_origin = train_origin[train_origin[\"set\"]==0].copy()\n",
    "train_origin = train_origin.reset_index(drop=True)\n",
    "\n",
    "# 1st stage\n",
    "train = pd.concat([\n",
    "    extract_candidate_dist(train_origin), \n",
    "    extract_candidate_tfidf_sim(train_origin, \"name+address+city\")\n",
    "])\n",
    "\n",
    "train = train.drop_duplicates(subset=[\"id\", \"match_id\"])\n",
    "train = add_orgin_data(train, train_origin)\n",
    "\n",
    "stage1_max_score = calc_max_score(train, train_origin)\n",
    "\n",
    "# 2nd stage\n",
    "train[\"habersine_dist\"] = haversine_np(train[\"longitude\"], train[\"latitude\"], train[\"match_longitude\"], train[\"match_latitude\"])\n",
    "\n",
    "# create target\n",
    "train['target'] = (train['point_of_interest'] == train['match_point_of_interest']).values.astype(int)\n",
    "train[\"target\"] = train[\"target\"].fillna(0)\n",
    "\n",
    "train = add_distance_features(train)\n",
    "train[\"category_venn\"] = train[[\"categories\", \"match_categories\"]].apply(lambda row: categorical_similarity(row.categories, row.match_categories), axis=1)\n",
    "\n",
    "# reduce memory\n",
    "train = train.drop(columns=['latitude', 'longitude', 'address', 'city', 'state', 'zip', 'country', 'url', 'phone',\n",
    "                            'match_latitude', 'match_longitude', 'match_address', 'match_city', 'match_state', \n",
    "                            'match_zip', 'match_country', 'match_url', 'match_phone'])\n",
    "gc.collect()\n",
    "\n",
    "# bert類似度\n",
    "bert_vec_categories = make_bert_vec(train_origin[[\"categories\"]], \"categories\")\n",
    "train = add_vec_sim_features(train, bert_vec_categories, \"bert\", \"categories\")\n",
    "del bert_vec_categories\n",
    "gc.collect()\n",
    "\n",
    "print(\"add_bert_sim_name\")\n",
    "bert_vec_name = make_bert_vec(train_origin[[\"name\"]], \"name\")\n",
    "train = add_vec_sim_features(train, bert_vec_name, \"bert\", \"name\")\n",
    "del bert_vec_name\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "not_use_cols = ['match_state_leven', 'address', 'categories', 'point_of_interest', 'match_address_leven',\n",
    "                'city', 'match_point_of_interest', 'match_name', 'match_categories_leven', 'match_longitude',\n",
    "                'target', 'match_city_leven', 'zip', 'match_categories', 'match_city', 'match_latitude',\n",
    "                'match_zip', 'match_url', 'id', 'match_set', 'country', 'match_state', 'match_address',\n",
    "                'match_name_leven', 'match_id', 'latitude', 'url', 'set', 'name', 'phone', 'longitude',\n",
    "                'match_url_leven', 'state', 'match_phone', 'match_country',\n",
    "                \"name+address+city\", \"match_name+address+city\"]\n",
    "features = [c for c in train.columns if c not in not_use_cols]\n",
    "#with open(OUTPUT_DIR + f'{exp_name}/features.pickle', 'wb') as f:\n",
    "#    pickle.dump(features, f)\n",
    "\n",
    "train = reduce_data_size(train, features)\n",
    "\n",
    "model = train_model(train, features, cv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [00:17<00:00, 11.88it/s]\n",
      "100%|██████████| 211/211 [00:36<00:00,  5.75it/s]\n",
      "203it [51:57, 15.36s/it] \n",
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 15479463/15479463 [04:21<00:00, 59294.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_bert_sim_name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 15479463/15479463 [05:08<00:00, 50127.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W] [01:42:44.638646] Treelite currently does not support float64 model parameters. Accuracy may degrade slightly relative to native LightGBM invocation.\n",
      "[W] [01:42:51.562849] Casting all thresholds and leaf values to float32, as FIL currently doesn't support inferencing models with float64 values. This may lead to predictions with reduced accuracy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/cupy/_creation/from_data.py:66: PerformanceWarning: Using synchronous transfer as pinned memory (3095892600 bytes) could not be allocated. This generally occurs because of insufficient host memory. The original error was: cudaErrorMemoryAllocation: out of memory\n",
      "  return _core.array(a, dtype, False, order)\n",
      "100%|██████████| 569406/569406 [00:00<00:00, 785068.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_score = 0.85293\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 1st stage\n",
    "st_time = datetime.datetime.now()\n",
    "test = pd.concat([\n",
    "    extract_candidate_dist(test_origin), \n",
    "    extract_candidate_tfidf_sim(test_origin, \"name\")\n",
    "])\n",
    "\n",
    "test = test.drop_duplicates(subset=[\"id\", \"match_id\"])\n",
    "test = test.loc[~pd.DataFrame(np.sort(test[[\"id\", \"match_id\"]].values,1 )).duplicated()].reset_index(drop=True)\n",
    "test = add_orgin_data(test, test_origin)\n",
    "\n",
    "# 2nd stage\n",
    "test[\"habersine_dist\"] = haversine_np(test[\"longitude\"], test[\"latitude\"], test[\"match_longitude\"], test[\"match_latitude\"])\n",
    "\n",
    "# create target\n",
    "test['target'] = (test['point_of_interest'] == test['match_point_of_interest']).values.astype(int)\n",
    "test[\"target\"] = test[\"target\"].fillna(0)\n",
    "\n",
    "test = add_distance_features(test)\n",
    "test[\"category_venn\"] = test[[\"categories\", \"match_categories\"]].apply(lambda row: categorical_similarity(row.categories, row.match_categories), axis=1)\n",
    "\n",
    "# reduce memory\n",
    "test = test.drop(columns=['latitude', 'longitude', 'address', 'city', 'state', 'zip', 'country', 'url', 'phone',\n",
    "                            'match_latitude', 'match_longitude', 'match_address', 'match_city', 'match_state', \n",
    "                            'match_zip', 'match_country', 'match_url', 'match_phone'])\n",
    "gc.collect()\n",
    "\n",
    "# bert類似度\n",
    "bert_vec_categories = make_bert_vec(test_origin[[\"categories\"]], \"categories\")\n",
    "test = add_vec_sim_features(test, bert_vec_categories, \"bert\", \"categories\")\n",
    "del bert_vec_categories\n",
    "gc.collect()\n",
    "\n",
    "print(\"add_bert_sim_name\")\n",
    "bert_vec_name = make_bert_vec(test_origin[[\"name\"]], \"name\")\n",
    "test = add_vec_sim_features(test, bert_vec_name, \"bert\", \"name\")\n",
    "del bert_vec_name\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "not_use_cols = ['match_state_leven', 'address', 'categories', 'point_of_interest', 'match_address_leven',\n",
    "                'city', 'match_point_of_interest', 'match_name', 'match_categories_leven', 'match_longitude',\n",
    "                'target', 'match_city_leven', 'zip', 'match_categories', 'match_city', 'match_latitude',\n",
    "                'match_zip', 'match_url', 'id', 'match_set', 'country', 'match_state', 'match_address',\n",
    "                'match_name_leven', 'match_id', 'latitude', 'url', 'set', 'name', 'phone', 'longitude',\n",
    "                'match_url_leven', 'state', 'match_phone', 'match_country']\n",
    "\n",
    "test = reduce_data_size(test, features)\n",
    "\n",
    "model.save_model(OUTPUT_DIR + f\"{exp_name}/cv_model.lgb\")\n",
    "pred = np.zeros(len(test))\n",
    "fi = ForestInference()\n",
    "fi = ForestInference.load(OUTPUT_DIR + f\"{exp_name}/cv_model.lgb\", output_class=True, model_type=\"lightgbm\")\n",
    "pred += fi.predict(test[features])\n",
    "test[\"prob\"] = pred\n",
    "\n",
    "test = transform_data(test, test_origin)\n",
    "test = postprocess(test)\n",
    "\n",
    "score = get_score(test, test_origin)\n",
    "print(f'cv_score = ' + '{:.5f}'.format(score))\n",
    "\n",
    "test.to_csv(OUTPUT_DIR + f\"{exp_name}/cv_oof.csv\", index=False)\n",
    "\n",
    "ed_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp038\n",
      "exp037からtfidfを飯田さんカスタムに\n",
      "stage1_max_score : 0.96829\n",
      "cv_score : 0.85293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = f'{exp_name}\\n'\n",
    "report += memo + '\\n'\n",
    "report += 'stage1_max_score : ' + '{:.5f}'.format(stage1_max_score) + '\\n'\n",
    "report += 'cv_score : ' + '{:.5f}'.format(score) + '\\n'\n",
    "report += f\"推論時間 : {str((ed_time - st_time).seconds/60)}分\" + '\\n'\n",
    "print(report)\n",
    "line_notify.send(report)\n",
    "slack_notify.send(report)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
