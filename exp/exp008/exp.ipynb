{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'local_train'\n",
    "#MODE = 'kaggle_inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'exp008'\n",
    "memo = 'exp006のペア裏削除'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "if MODE == 'local_train':\n",
    "    sys.path.append('/home/kaggler/.local/lib/python3.8/site-packages')\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv\n",
    "    sys.path.append(os.getenv('UTILS_PATH'))\n",
    "    import line_notify\n",
    "    import slack_notify\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.style.use(\"ggplot\")\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import canberra\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import multiprocessing\n",
    "import Levenshtein\n",
    "import difflib\n",
    "import pickle\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directry_setting\n",
    "if MODE == 'local_train':\n",
    "    INPUT_DIR = os.getenv('INPUT_DIR')\n",
    "    OUTPUT_DIR = os.getenv('OUTPUT_DIR')\n",
    "    MODEL_DIR = os.getenv('OUTPUT_DIR')\n",
    "    os.makedirs(OUTPUT_DIR + exp_name, exist_ok=True)\n",
    "\n",
    "elif MODE == 'kaggle_inference':\n",
    "    INPUT_DIR = '/kaggle/input/foursquare-location-matching/'\n",
    "    OUTPUT_DIR = './'\n",
    "    MODEL_DIR = f'../input/fs{exp_name}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "SEED = 42\n",
    "N_NEIGHBORS = 10\n",
    "N_SPLITS = 5\n",
    "PROB_TH = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    columns = ['id', 'name', 'address', 'city', 'state',\n",
    "        'zip', 'country', 'url', 'phone', 'categories']\n",
    "    for c in columns:\n",
    "        if c != \"id\":\n",
    "            df[c] = df[c].astype(str).str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate(df):\n",
    "    dfs = []\n",
    "    candidates = pd.DataFrame()\n",
    "    for country, country_df in df.groupby(\"country\"):\n",
    "        country_df = country_df.reset_index(drop=True)\n",
    "        \n",
    "        knn = KNeighborsRegressor(n_neighbors=min(len(country_df), N_NEIGHBORS), \n",
    "                                  metric='haversine', n_jobs=-1)\n",
    "        knn.fit(country_df[['latitude','longitude']], country_df.index)\n",
    "        dists, nears = knn.kneighbors(country_df[['latitude','longitude']], return_distance=True)\n",
    "        \n",
    "        k = min(len(country_df), N_NEIGHBORS)\n",
    "        country_df['match_id'] = country_df['id'].values[nears[:, :k]].tolist()\n",
    "        country_df['d_near'] = dists[:, :k].tolist()\n",
    "        country_df = country_df.explode(['match_id','d_near'])\n",
    "        b_len = len(country_df)\n",
    "        country_df = country_df.loc[country_df['id'] != country_df['match_id']].copy()\n",
    "        country_df = country_df.loc[~pd.DataFrame(np.sort(country_df[['id','match_id']].values,1)).duplicated()].reset_index(drop=True)\n",
    "        a_len = len(country_df)\n",
    "        print(country, b_len, a_len)\n",
    "\n",
    "        dfs.append(country_df)\n",
    "    df = pd.concat(dfs).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_orgin_data(df, org_df):\n",
    "    df = df.merge(org_df.add_prefix('match_'), on='match_id')\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/columbia2131/foursquare-iou-metrics\n",
    "def get_id2poi(input_df: pd.DataFrame) -> dict:\n",
    "    return dict(zip(input_df['id'], input_df['point_of_interest']))\n",
    "\n",
    "def get_poi2ids(input_df: pd.DataFrame) -> dict:\n",
    "    return input_df.groupby('point_of_interest')['id'].apply(set).to_dict()\n",
    "\n",
    "def get_score(input_df: pd.DataFrame, org_data):\n",
    "    scores = []\n",
    "    id2poi = get_id2poi(org_data)\n",
    "    poi2ids = get_poi2ids(org_data)\n",
    "    for id_str, matches in zip(input_df['id'].to_numpy(), input_df['matches'].to_numpy()):\n",
    "        targets = poi2ids[id2poi[id_str]]\n",
    "        preds = set(matches.split())\n",
    "        score = len((targets & preds)) / len((targets | preds))\n",
    "        scores.append(score)\n",
    "    scores = np.array(scores)\n",
    "    return scores.mean()\n",
    "\n",
    "def calc_max_score(tr_data, org_data):\n",
    "    train_candidate = pd.DataFrame()\n",
    "    train_candidate['id'] = org_data['id'].unique()\n",
    "    train_candidate['matches'] = org_data['id'].unique()\n",
    "    idx = tr_data['point_of_interest']==tr_data['match_point_of_interest']\n",
    "    train_match = tr_data.loc[idx].groupby('id')['match_id'].apply(list).map(\" \".join).reset_index()\n",
    "    train_match.columns = ['id','candidates']\n",
    "    train_candidate = train_candidate.merge(train_match, on = 'id', how = 'left')\n",
    "    idx = ~train_candidate['candidates'].isna()\n",
    "    train_candidate.loc[idx, \"matches\"] += \" \" + train_candidate.loc[idx, \"candidates\"]\n",
    "    score = get_score(train_candidate, org_data)\n",
    "    print('1st_stage_max_score : ' + '{:.5f}'.format(score))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def LCS(str S, str T):\n",
    "    cdef int i, j\n",
    "    cdef list dp = [[0] * (len(T) + 1) for _ in range(len(S) + 1)]\n",
    "    for i in range(len(S)):\n",
    "        for j in range(len(T)):\n",
    "            dp[i + 1][j + 1] = max(dp[i][j] + (S[i] == T[j]), dp[i + 1][j], dp[i][j + 1], dp[i + 1][j + 1])\n",
    "    return dp[len(S)][len(T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_distance_features(args):\n",
    "    _, df = args\n",
    "\n",
    "    columns = ['name', 'address', 'city', 'state',\n",
    "               'zip', 'country', 'url', 'phone', 'categories']\n",
    "\n",
    "    for c in columns:\n",
    "        geshs = []\n",
    "        levens = []\n",
    "        jaros = []\n",
    "        lcss = []\n",
    "        for str1, str2 in df[[f\"{c}\", f\"match_{c}\"]].values.astype(str):\n",
    "            if str1==str1 and str2==str2:\n",
    "                geshs.append(difflib.SequenceMatcher(None, str1, str2).ratio())\n",
    "                levens.append(Levenshtein.distance(str1, str2))\n",
    "                jaros.append(Levenshtein.jaro_winkler(str1, str2))\n",
    "                lcss.append(LCS(str(str1), str(str2)))\n",
    "            else:\n",
    "                geshs.append(-1)\n",
    "                levens.append(-1)\n",
    "                jaros.append(-1)\n",
    "        df[f\"match_{c}_gesh\"] = geshs\n",
    "        df[f\"match_{c}_leven\"] = levens\n",
    "        df[f\"match_{c}_jaro\"] = jaros\n",
    "        df[f\"match_{c}_lcs\"] = lcss\n",
    "            \n",
    "        if not c in ['country', \"phone\", \"zip\"]:\n",
    "            df[f\"match_{c}_len\"] = df[f\"match_{c}\"].astype(str).map(len)\n",
    "            df[f\"match_{c}_nleven\"] = df[f\"match_{c}_leven\"] / df[f\"match_{c}_len\"]\n",
    "            df[f\"match_{c}_nlcsi\"] = df[f\"match_{c}_lcs\"] / df[f\"match_{c}_len\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_distance_features(df):\n",
    "    processes = multiprocessing.cpu_count()\n",
    "    with multiprocessing.Pool(processes=processes) as pool:\n",
    "        dfs = pool.imap_unordered(_add_distance_features, df.groupby('country'))\n",
    "        dfs = tqdm(dfs)\n",
    "        dfs = list(dfs)\n",
    "    df = pd.concat(dfs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_data_size(df, features):\n",
    "    if MODE == 'local_train':\n",
    "        df = df[features + ['target', 'id', 'match_id']].copy()\n",
    "    elif MODE == 'kaggle_inference':\n",
    "        df = df[features + ['id', 'match_id']].copy()\n",
    "\n",
    "\n",
    "    df[features] = df[features].astype(np.float16)\n",
    "    for _ in range(5):\n",
    "        gc.collect()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, features):\n",
    "    params = {'objective': 'binary', \n",
    "              'boosting': 'gbdt',\n",
    "              'learning_rate': 0.1, \n",
    "              'metric': 'binary_logloss', \n",
    "              'seed': SEED, \n",
    "              'feature_pre_filter': False, \n",
    "              'lambda_l1': 0.5745709668124809, \n",
    "              'lambda_l2': 0.5123383865042099, \n",
    "              'num_leaves': 239, \n",
    "              'feature_fraction': 0.784, \n",
    "              'bagging_fraction': 1.0, \n",
    "              'bagging_freq': 0, \n",
    "              'min_child_samples': 5\n",
    "              }\n",
    "\n",
    "    # split folds\n",
    "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    for i, (trn_idx, val_idx) in enumerate(kf.split(df, df[\"target\"], df[\"target\"])):\n",
    "        df.loc[val_idx, \"fold\"] = i\n",
    "    \n",
    "    fi = pd.DataFrame()\n",
    "    oof = df[['id', 'match_id', 'target']].copy()\n",
    "    oof['prob'] = 0.0\n",
    "    scores = []\n",
    "\n",
    "    for i in range(N_SPLITS):\n",
    "        print('fold : ' + str(i))\n",
    "        tr_idx = df[df['fold'] != i].index\n",
    "        vl_idx = df[df['fold'] == i].index\n",
    "        tr_x, tr_y = df.loc[tr_idx, features], df.loc[tr_idx, 'target']\n",
    "        vl_x, vl_y = df.loc[vl_idx, features], df.loc[vl_idx, 'target']\n",
    "        tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "        vl_data = lgb.Dataset(vl_x, label=vl_y)\n",
    "\n",
    "        model = lgb.train(params, tr_data, valid_sets=[tr_data, vl_data],\n",
    "                        num_boost_round=20000, early_stopping_rounds=100, verbose_eval=1000)\n",
    "\n",
    "        # 特徴量重要度\n",
    "        fi_tmp = pd.DataFrame()\n",
    "        fi_tmp['feature'] = model.feature_name()\n",
    "        fi_tmp['importance'] = model.feature_importance(importance_type='gain')\n",
    "        fi_tmp['iter'] = i\n",
    "        fi = fi.append(fi_tmp)\n",
    "\n",
    "        pred = model.predict(vl_x, num_iteration=model.best_iteration)\n",
    "        oof.loc[vl_idx, 'prob'] = pred\n",
    "\n",
    "        score = accuracy_score((pred > PROB_TH).astype(int), vl_y)\n",
    "        scores.append(score)\n",
    "        print(f'fold{i} | accuracy = ' + '{:.5f}'.format(score))\n",
    "\n",
    "        with open(OUTPUT_DIR + f'{exp_name}/model{i}.pickle', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        \n",
    "    oof.to_csv(OUTPUT_DIR + f'{exp_name}/{exp_name}_oof.csv', index=False)\n",
    "\n",
    "    print('accuracy(mean) : ' + '{:.5f}'.format(np.mean(scores)))\n",
    "    print(scores)\n",
    "\n",
    "    fi_n = fi['feature'].nunique()\n",
    "    order = list(fi.groupby(\"feature\").mean().sort_values(\"importance\", ascending=False).index)\n",
    "    plt.figure(figsize=(10, fi_n*0.2))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=fi, order=order)\n",
    "    plt.title(f\"LGBM importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR + f'{exp_name}/lgbm_importance.png')\n",
    "\n",
    "    return oof, np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(df, features):\n",
    "    pred = np.zeros(len(df))\n",
    "    for i in range(N_SPLITS):\n",
    "        with open(MODEL_DIR + f'model{i}.pickle', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        pred += model.predict(df[features], num_iteration=model.best_iteration) / N_SPLITS\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df, org_data):\n",
    "    train_candidate = pd.DataFrame()\n",
    "    train_candidate['id'] = org_data['id'].unique()\n",
    "    train_candidate['matches'] = org_data['id'].unique()\n",
    "\n",
    "    train_match = df[df['prob'] >= PROB_TH].copy()\n",
    "    train_match = train_match.groupby('id')['match_id'].apply(list).map(\" \".join).reset_index()\n",
    "    train_match.columns = ['id','candidates']\n",
    "    train_candidate = train_candidate.merge(train_match, on = 'id', how = 'left')\n",
    "    idx = ~train_candidate['candidates'].isna()\n",
    "    train_candidate.loc[idx, \"matches\"] += \" \" + train_candidate.loc[idx, \"candidates\"]\n",
    "    return train_candidate[['id', 'matches']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(df):\n",
    "    id2match = dict(zip(df[\"id\"].values, df[\"matches\"].str.split()))\n",
    "\n",
    "    for match in tqdm(df[\"matches\"]):\n",
    "        match = match.split()\n",
    "        if len(match) == 1:        \n",
    "            continue\n",
    "\n",
    "        base = match[0]\n",
    "        for m in match[1:]:\n",
    "            if not base in id2match[m]:\n",
    "                id2match[m].append(base)\n",
    "    df[\"matches\"] = df[\"id\"].map(id2match).map(\" \".join)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train():\n",
    "    train_origin = pd.read_csv(INPUT_DIR + \"train.csv\")\n",
    "    train_origin = preprocess(train_origin)\n",
    "\n",
    "    # trainデータの分割\n",
    "    kf = GroupKFold(n_splits=2)\n",
    "    for i, (trn_idx, val_idx) in enumerate(kf.split(train_origin, train_origin['point_of_interest'], train_origin['point_of_interest'])):\n",
    "        train_origin.loc[val_idx, \"set\"] = i\n",
    "\n",
    "    # 1st stage\n",
    "    train = pd.concat([\n",
    "        extract_candidate(train_origin[train_origin[\"set\"]==0]), \n",
    "        extract_candidate(train_origin[train_origin[\"set\"]==1]), \n",
    "    ])\n",
    "    train = add_orgin_data(train, train_origin)\n",
    "    stage1_max_score = calc_max_score(train, train_origin)\n",
    "\n",
    "    # 2nd stage\n",
    "    # create target\n",
    "    train['target'] = (train['point_of_interest'] == train['match_point_of_interest']).values.astype(int)\n",
    "    train[\"target\"] = train[\"target\"].fillna(0)\n",
    "\n",
    "    train = add_distance_features(train)\n",
    "\n",
    "    not_use_cols = ['match_state_leven', 'address', 'categories', 'point_of_interest', 'match_address_leven',\n",
    "                    'city', 'match_point_of_interest', 'match_name', 'match_categories_leven', 'match_longitude',\n",
    "                    'target', 'match_city_leven', 'zip', 'match_categories', 'match_city', 'match_latitude',\n",
    "                    'match_zip', 'match_url', 'id', 'match_set', 'country', 'match_state', 'match_address',\n",
    "                    'match_name_leven', 'match_id', 'latitude', 'url', 'set', 'name', 'phone', 'longitude',\n",
    "                    'match_url_leven', 'state', 'match_phone', 'match_country']\n",
    "    features = [c for c in train.columns if c not in not_use_cols]\n",
    "    with open(OUTPUT_DIR + f'{exp_name}/features.pickle', 'wb') as f:\n",
    "        pickle.dump(features, f)\n",
    "\n",
    "    train = reduce_data_size(train, features)\n",
    "\n",
    "    oof, stage2_mean_accuracy = train_model(train, features)\n",
    "    oof = transform_data(oof, train_origin)\n",
    "\n",
    "    cv_score = get_score(oof, train_origin)\n",
    "    print(f'cv_score = ' + '{:.5f}'.format(cv_score))\n",
    "\n",
    "    oof = postprocess(oof)\n",
    "    cv_score_after_pp = get_score(oof, train_origin)\n",
    "    print(f'cv_score(after_pp) = ' + '{:.5f}'.format(cv_score_after_pp))\n",
    "\n",
    "\n",
    "    report = f'{exp_name}\\n'\n",
    "    report += memo + '\\n'\n",
    "    report += 'stage1_max_score : ' + '{:.5f}'.format(stage1_max_score) + '\\n'\n",
    "    report += 'stage2_mean_accuracy : ' + '{:.5f}'.format(stage2_mean_accuracy) + '\\n'\n",
    "    report += 'cv_score : ' + '{:.5f}'.format(cv_score) + '\\n'\n",
    "    report += 'cv_score_after_pp : ' + '{:.5f}'.format(cv_score_after_pp) + '\\n'\n",
    "    print(report)\n",
    "    line_notify.send(report)\n",
    "    slack_notify.send(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference():\n",
    "    test_origin = pd.read_csv(INPUT_DIR + \"test.csv\")\n",
    "    \n",
    "    if len(test_origin) == 5:\n",
    "        test_origin = pd.read_csv(INPUT_DIR + \"train.csv\")\n",
    "        kf = GroupKFold(n_splits=2)\n",
    "        for i, (trn_idx, val_idx) in enumerate(kf.split(test_origin, test_origin['point_of_interest'], test_origin['point_of_interest'])):\n",
    "            test_origin = test_origin.loc[trn_idx]\n",
    "            break\n",
    "\n",
    "    test_origin = preprocess(test_origin)\n",
    "\n",
    "    # 1st stage\n",
    "    test = extract_candidate(test_origin)\n",
    "\n",
    "    # 2nd stage\n",
    "    test = add_orgin_data(test, test_origin)\n",
    "    test = add_distance_features(test)\n",
    "    with open(MODEL_DIR + 'features.pickle', 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    test = reduce_data_size(test, features)\n",
    "    \n",
    "    print('test_dataset_info')\n",
    "    print(test.info())\n",
    "    \n",
    "    test['prob'] = model_inference(test, features)\n",
    "    test = transform_data(test, test_origin)\n",
    "    test = postprocess(test)\n",
    "    test.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad 120 108\n",
      "ae 19860 17298\n",
      "af 81 72\n",
      "ag 64 56\n",
      "ai 9 4\n",
      "al 290 261\n",
      "am 580 504\n",
      "an 4 1\n",
      "ao 64 56\n",
      "aq 16 9\n",
      "ar 24900 21564\n",
      "at 12190 10566\n",
      "au 51850 44784\n",
      "aw 280 252\n",
      "ax 64 56\n",
      "az 1990 1737\n",
      "ba 620 540\n",
      "bb 390 351\n",
      "bd 680 594\n",
      "be 129440 111870\n",
      "bf 4 1\n",
      "bg 8130 7092\n",
      "bh 2220 1944\n",
      "bi 16 12\n",
      "bj 4 1\n",
      "bl 150 126\n",
      "bm 140 117\n",
      "bn 3480 2988\n",
      "bo 890 774\n",
      "bq 1 0\n",
      "br 257870 222219\n",
      "bs 460 405\n",
      "bt 25 16\n",
      "bw 100 81\n",
      "by 9170 7857\n",
      "bz 130 108\n",
      "ca 59540 51417\n",
      "cd 25 20\n",
      "ch 11160 9738\n",
      "ci 9 4\n",
      "cl 38360 33246\n",
      "cm 36 30\n",
      "cn 38020 33102\n",
      "co 17850 15525\n",
      "cr 7710 6669\n",
      "cu 130 108\n",
      "cv 64 56\n",
      "cw 64 56\n",
      "cy 7960 6876\n",
      "cz 24760 21393\n",
      "de 89900 77886\n",
      "dk 8660 7515\n",
      "dm 49 42\n",
      "do 5640 4905\n",
      "dz 81 72\n",
      "ec 3290 2853\n",
      "ee 4730 4140\n",
      "eg 16450 14301\n",
      "es 64000 55404\n",
      "et 150 135\n",
      "fi 32790 28467\n",
      "fj 160 135\n",
      "fo 4 1\n",
      "fr 70610 61218\n",
      "gb 129390 111798\n",
      "gd 36 30\n",
      "ge 2080 1800\n",
      "gf 16 12\n",
      "gg 81 72\n",
      "gh 650 558\n",
      "gi 100 81\n",
      "gm 4 1\n",
      "gp 250 216\n",
      "gq 4 1\n",
      "gr 28340 24732\n",
      "gt 2250 1935\n",
      "gu 920 819\n",
      "hk 25210 21807\n",
      "hn 1250 1080\n",
      "hr 4610 4023\n",
      "ht 36 30\n",
      "hu 15820 13707\n",
      "id 550480 475804\n",
      "ie 8320 7164\n",
      "il 4760 4113\n",
      "im 240 207\n",
      "in 23650 20439\n",
      "iq 400 351\n",
      "ir 18000 15435\n",
      "is 1350 1188\n",
      "it 56860 49032\n",
      "je 64 56\n",
      "jm 1170 981\n",
      "jo 2090 1782\n",
      "jp 353680 305667\n",
      "ke 2030 1791\n",
      "kg 460 405\n",
      "kh 1750 1512\n",
      "kn 1 0\n",
      "kp 100 90\n",
      "kr 96250 83115\n",
      "kw 19580 16983\n",
      "ky 170 153\n",
      "kz 1890 1674\n",
      "la 680 594\n",
      "lb 1610 1395\n",
      "lc 140 126\n",
      "li 49 42\n",
      "lk 2590 2241\n",
      "lr 4 1\n",
      "lt 2440 2097\n",
      "lu 870 774\n",
      "lv 12890 11124\n",
      "ly 16 9\n",
      "ma 1450 1260\n",
      "mc 240 216\n",
      "md 2750 2358\n",
      "me 1410 1233\n",
      "mf 4 1\n",
      "mg 25 20\n",
      "mk 5390 4689\n",
      "mm 940 819\n",
      "mn 620 549\n",
      "mo 600 513\n",
      "mp 220 189\n",
      "mq 1560 1350\n",
      "mt 1160 1008\n",
      "mu 270 243\n",
      "mv 4220 3654\n",
      "mw 64 56\n",
      "mx 104990 90675\n",
      "my 232570 201204\n",
      "mz 160 144\n",
      "nan 25 16\n",
      "nc 9 6\n",
      "ne 4 1\n",
      "ng 650 558\n",
      "ni 580 513\n",
      "nl 38630 33426\n",
      "no 4890 4275\n",
      "np 250 216\n",
      "nz 6130 5283\n",
      "om 1120 972\n",
      "pa 2420 2088\n",
      "pe 13220 11430\n",
      "pf 81 72\n",
      "pg 4 1\n",
      "ph 111970 96804\n",
      "pk 920 810\n",
      "pl 12910 11088\n",
      "pm 1 0\n",
      "pr 5600 4887\n",
      "ps 25 20\n",
      "pt 13160 11412\n",
      "pw 4 1\n",
      "py 7890 6840\n",
      "qa 2520 2151\n",
      "re 150 135\n",
      "ro 17200 14850\n",
      "rs 7250 6255\n",
      "ru 285060 246519\n",
      "rw 100 90\n",
      "sa 54600 47295\n",
      "sc 36 30\n",
      "sd 230 207\n",
      "se 17370 15030\n",
      "sg 104650 90432\n",
      "sh 4 1\n",
      "si 1640 1422\n",
      "sk 4830 4230\n",
      "sl 1 0\n",
      "sm 100 90\n",
      "sn 25 20\n",
      "so 9 6\n",
      "sr 81 72\n",
      "ss 1 0\n",
      "st 4 1\n",
      "sv 2280 1962\n",
      "sx 49 36\n",
      "sy 160 144\n",
      "sz 9 6\n",
      "tc 49 42\n",
      "th 292210 252126\n",
      "tj 4 1\n",
      "tl 25 16\n",
      "tm 450 396\n",
      "tn 2670 2313\n",
      "tr 578410 499723\n",
      "tt 1010 891\n",
      "tw 22600 19548\n",
      "tz 320 279\n",
      "ua 48630 41877\n",
      "ug 300 270\n",
      "us 1224690 1056504\n",
      "uy 1880 1611\n",
      "uz 580 495\n",
      "va 36 30\n",
      "vc 64 56\n",
      "ve 6320 5454\n",
      "vg 36 30\n",
      "vi 360 315\n",
      "vn 16360 14058\n",
      "ws 81 64\n",
      "xk 140 126\n",
      "xx 1100 963\n",
      "ye 4 1\n",
      "yt 1 0\n",
      "za 12930 11286\n",
      "zm 64 56\n",
      "zw 9 4\n",
      "ad 64 49\n",
      "ae 19940 17289\n",
      "af 100 81\n",
      "ag 25 16\n",
      "ai 25 16\n",
      "al 290 261\n",
      "am 740 648\n",
      "an 1 0\n",
      "ao 49 42\n",
      "aq 130 108\n",
      "ar 27650 24057\n",
      "at 13090 11295\n",
      "au 52640 45486\n",
      "aw 350 306\n",
      "ax 140 117\n",
      "az 2070 1773\n",
      "ba 560 486\n",
      "bb 460 405\n",
      "bd 730 639\n",
      "be 128770 111765\n",
      "bf 36 30\n",
      "bg 8310 7200\n",
      "bh 2230 1953\n",
      "bl 16 9\n",
      "bm 120 108\n",
      "bn 3690 3114\n",
      "bo 970 837\n",
      "bq 4 1\n",
      "br 254540 220104\n",
      "bs 400 360\n",
      "bt 25 20\n",
      "bv 1 0\n",
      "bw 110 99\n",
      "by 9220 7902\n",
      "bz 160 135\n",
      "ca 59730 51606\n",
      "cd 36 30\n",
      "ch 10910 9468\n",
      "ci 36 30\n",
      "cl 39520 34173\n",
      "cm 49 42\n",
      "cn 36430 31473\n",
      "co 17390 15075\n",
      "cr 7900 6849\n",
      "cu 290 252\n",
      "cv 16 9\n",
      "cw 100 90\n",
      "cy 6640 5724\n",
      "cz 24440 21033\n",
      "de 88230 76455\n",
      "dj 4 1\n",
      "dk 8570 7416\n",
      "dm 25 20\n",
      "do 5390 4626\n",
      "dz 64 56\n",
      "ec 2910 2547\n",
      "ee 4580 3933\n",
      "eg 15110 13014\n",
      "eh 4 1\n",
      "es 65230 56304\n",
      "et 64 49\n",
      "eu 1 0\n",
      "fi 33550 28926\n",
      "fj 16 12\n",
      "fr 71130 61290\n",
      "ga 1 0\n",
      "gb 126050 108666\n",
      "gd 49 42\n",
      "ge 2210 1908\n",
      "gf 130 117\n",
      "gg 150 126\n",
      "gh 310 270\n",
      "gi 36 30\n",
      "gl 16 9\n",
      "gm 4 1\n",
      "gp 180 153\n",
      "gr 30160 26127\n",
      "gt 2180 1890\n",
      "gu 990 855\n",
      "gw 4 1\n",
      "gy 1 0\n",
      "hk 25550 22293\n",
      "hn 1080 909\n",
      "hr 5140 4473\n",
      "ht 110 90\n",
      "hu 16880 14760\n",
      "id 557480 481211\n",
      "ie 8340 7236\n",
      "il 4720 4041\n",
      "im 180 162\n",
      "in 22810 19692\n",
      "iq 410 369\n",
      "ir 19220 16650\n",
      "is 1650 1458\n",
      "it 57090 49410\n",
      "je 140 126\n",
      "jm 920 792\n",
      "jo 1990 1719\n",
      "jp 346640 299376\n",
      "ke 1940 1656\n",
      "kg 460 414\n",
      "kh 1680 1440\n",
      "kn 49 42\n",
      "kp 16 12\n",
      "kr 94620 81621\n",
      "kw 18350 15921\n",
      "ky 130 117\n",
      "kz 1790 1566\n",
      "la 690 612\n",
      "lb 1580 1368\n",
      "lc 140 126\n",
      "li 9 4\n",
      "lk 2450 2124\n",
      "lt 2300 1998\n",
      "lu 880 747\n",
      "lv 13410 11583\n",
      "ly 1 0\n",
      "ma 1770 1539\n",
      "mc 200 180\n",
      "md 2630 2295\n",
      "me 1410 1179\n",
      "mf 64 56\n",
      "mg 64 56\n",
      "mk 5180 4500\n",
      "mm 570 504\n",
      "mn 580 513\n",
      "mo 770 684\n",
      "mp 49 42\n",
      "mq 1580 1341\n",
      "mt 1200 1044\n",
      "mu 300 252\n",
      "mv 3730 3204\n",
      "mw 25 16\n",
      "mx 108970 94338\n",
      "my 230690 199395\n",
      "mz 110 90\n",
      "nan 36 30\n",
      "nc 4 1\n",
      "ne 4 1\n",
      "ng 650 576\n",
      "ni 730 630\n",
      "nl 38500 33309\n",
      "no 4820 4149\n",
      "np 430 378\n",
      "nz 6390 5571\n",
      "om 1200 1035\n",
      "pa 2690 2322\n",
      "pe 13690 11835\n",
      "pf 170 144\n",
      "pg 4 1\n",
      "ph 109830 95148\n",
      "pk 1040 918\n",
      "pl 12810 10908\n",
      "pr 6130 5265\n",
      "ps 100 90\n",
      "pt 13940 12123\n",
      "py 7490 6390\n",
      "qa 2420 2124\n",
      "re 100 90\n",
      "ro 17480 15111\n",
      "rs 7040 6048\n",
      "ru 285240 246204\n",
      "rw 4 1\n",
      "sa 54070 46575\n",
      "sc 100 90\n",
      "sd 140 117\n",
      "se 16580 14328\n",
      "sg 105400 90792\n",
      "si 1530 1350\n",
      "sj 4 1\n",
      "sk 4550 3942\n",
      "sm 160 135\n",
      "sn 25 20\n",
      "so 9 4\n",
      "sr 36 30\n",
      "sv 1920 1665\n",
      "sx 16 12\n",
      "sy 260 225\n",
      "sz 16 12\n",
      "tc 150 126\n",
      "tg 4 1\n",
      "th 295870 255807\n",
      "tj 4 1\n",
      "tl 9 6\n",
      "tm 600 504\n",
      "tn 2460 2142\n",
      "to 9 6\n",
      "tr 573360 495893\n",
      "tt 1000 873\n",
      "tw 23460 20223\n",
      "tz 400 333\n",
      "ua 50010 43353\n",
      "ug 200 171\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3881/3247393611.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mMODE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'local_train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mMODE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'kaggle_inference'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrun_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3881/676123748.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     train = pd.concat([\n\u001b[1;32m     12\u001b[0m         \u001b[0mextract_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_origin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_origin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"set\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mextract_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_origin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_origin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"set\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     ])\n\u001b[1;32m     15\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_orgin_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_origin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3881/3026618601.py\u001b[0m in \u001b[0;36mextract_candidate\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      8\u001b[0m                                   metric='haversine', n_jobs=-1)\n\u001b[1;32m      9\u001b[0m         \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latitude'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountry_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnears\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latitude'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_NEIGHBORS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m                 \u001b[0mparallel_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"prefer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"threads\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             chunked_results = Parallel(n_jobs, **parallel_kwargs)(\n\u001b[0m\u001b[1;32m    723\u001b[0m                 delayed(_tree_query_parallel_helper)(\n\u001b[1;32m    724\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if MODE == 'local_train':\n",
    "    run_train()\n",
    "elif MODE == 'kaggle_inference':\n",
    "    run_inference()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
